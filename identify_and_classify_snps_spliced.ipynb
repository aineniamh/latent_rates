{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "import collections\n",
    "from collections import Counter\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAXML TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw=open('spliced_cds_work/EBOV_CDS_splice_39_seqs_underscores.fa','w')\n",
    "with open('spliced_cds_work/EBOV_CDS_splice_39_seqs.fa','r') as f:\n",
    "    for l in f:\n",
    "        l=l.rstrip('\\n')\n",
    "        l=l.replace('|','_')\n",
    "        fw.write(l+'\\n')\n",
    "fw.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAxML can't, parse the alignment file as phylip file \n",
      "it will now try to parse it as FASTA file\n",
      "\n",
      "\n",
      "\n",
      "Bootstrap[997]: Time 0.162552 seconds, bootstrap likelihood -25060.890666, best rearrangement setting 15\n",
      "Bootstrap[998]: Time 0.172141 seconds, bootstrap likelihood -24921.542504, best rearrangement setting 5\n",
      "Bootstrap[999]: Time 0.149512 seconds, bootstrap likelihood -24833.443591, best rearrangement setting 6\n",
      "\n",
      "\n",
      "Overall Time for 1000 Rapid Bootstraps 167.961885 seconds\n",
      "Average Time per Rapid Bootstrap 0.167962 seconds\n",
      "\n",
      "Starting ML Search ...\n",
      "\n",
      "Fast ML optimization finished\n",
      "\n",
      "Fast ML search Time: 62.350852 seconds\n",
      "\n",
      "Slow ML Search 0 Likelihood: -24971.957508\n",
      "Slow ML Search 1 Likelihood: -24971.957508\n",
      "Slow ML Search 2 Likelihood: -24971.957514\n",
      "Slow ML Search 3 Likelihood: -24971.957518\n",
      "Slow ML Search 4 Likelihood: -24971.957512\n",
      "Slow ML Search 5 Likelihood: -24971.957528\n",
      "Slow ML Search 6 Likelihood: -24971.957527\n",
      "Slow ML Search 7 Likelihood: -24971.957525\n",
      "Slow ML Search 8 Likelihood: -24971.957536\n",
      "Slow ML Search 9 Likelihood: -24971.957529\n",
      "Slow ML optimization finished\n",
      "\n",
      "Slow ML search Time: 3.759727 seconds\n",
      "Thorough ML search Time: 0.750423 seconds\n",
      "\n",
      "Final ML Optimization Likelihood: -24971.963735\n",
      "\n",
      "Model Information:\n",
      "\n",
      "Model Parameters of Partition 0, Name: No Name Provided, Type of Data: DNA\n",
      "alpha: 0.338702\n",
      "Tree-Length: 0.069799\n",
      "rate A <-> C: 1.305025\n",
      "rate A <-> G: 10.970943\n",
      "rate A <-> T: 0.804794\n",
      "rate C <-> G: 0.170081\n",
      "rate C <-> T: 12.570582\n",
      "rate G <-> T: 1.000000\n",
      "\n",
      "freq pi(A): 0.308063\n",
      "freq pi(C): 0.221652\n",
      "freq pi(G): 0.210047\n",
      "freq pi(T): 0.260238\n",
      "\n",
      "\n",
      "ML search took 66.862018 secs or 0.018573 hours\n",
      "\n",
      "Combined Bootstrap and ML search took 234.823967 secs or 0.065229 hours\n",
      "\n",
      "Drawing Bootstrap Support Values on best-scoring ML tree ...\n",
      "\n",
      "\n",
      "\n",
      "Found 1 tree in File /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bestTree.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "\n",
      "\n",
      "Found 1 tree in File /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bestTree.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "Program execution info written to /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_info.raxml_rapid_spliced_cds_tree\n",
      "All 1000 bootstrapped trees written to: /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bootstrap.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "Best-scoring ML tree written to: /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bestTree.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "Best-scoring ML tree with support values written to: /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bipartitions.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "Best-scoring ML tree with support values as branch labels written to: /Users/aineniamhotoole/Google Drive/phd/latent_rates/spliced_cds_work/RAxML_bipartitionsBranchLabels.raxml_rapid_spliced_cds_tree\n",
      "\n",
      "Overall execution time for full ML analysis: 235.000972 secs or 0.065278 hours or 0.002720 days\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd spliced_cds_work/\n",
    "raxmlHPC-PTHREADS -f a -x 12345 -p 12345 -\\# 1000 -m GTRGAMMA -s EBOV_CDS_splice_39_seqs_underscores.fa -n raxml_rapid_spliced_cds_tree -o EBOV_AF272001_Mayinga_Yambuku_DRC_1976,EBOV_KC242801_deRoover_DRC_1976,EBOV_KC242791_Bonduni_Tandala_DRC_1977 -T 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANCESTRAL RECONSTRUCTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAxML can't, parse the alignment file as phylip file \n",
      "it will now try to parse it as FASTA file\n",
      "\n",
      "\n",
      "\n",
      "Found 5 sequences that are exactly identical to other sequences in the alignment.\n",
      "Normally they should be excluded from the analysis.\n",
      "\n",
      "An alignment file with sequence duplicates removed has already\n",
      "been printed to file EBOV_CDS_splice_39_seqs_underscores.fa.reduced\n",
      "\n",
      "\n",
      "Using BFGS method to optimize GTR rate parameters, to disable this specify \"--no-bfgs\" \n",
      "\n",
      "\n",
      "This is the RAxML Master Pthread\n",
      "\n",
      "This is RAxML Worker Pthread Number: 1\n",
      "\n",
      "This is RAxML Worker Pthread Number: 2\n",
      "\n",
      "\n",
      "This is RAxML version 8.2.11 released by Alexandros Stamatakis on June 2017.\n",
      "\n",
      "With greatly appreciated code contributions by:\n",
      "Andre Aberer      (HITS)\n",
      "Simon Berger      (HITS)\n",
      "Alexey Kozlov     (HITS)\n",
      "Kassian Kobert    (HITS)\n",
      "David Dao         (KIT and HITS)\n",
      "Sarah Lutteropp   (KIT and HITS)\n",
      "Nick Pattengale   (Sandia)\n",
      "Wayne Pfeiffer    (SDSC)\n",
      "Akifumi S. Tanabe (NRIFS)\n",
      "Charlie Taylor    (UF)\n",
      "\n",
      "\n",
      "Alignment has 305 distinct alignment patterns\n",
      "\n",
      "Proportion of gaps and completely undetermined characters in this alignment: 4.68%\n",
      "\n",
      "RAxML marginal ancestral state computation\n",
      "\n",
      "Using 1 distinct models/data partitions with joint branch length optimization\n",
      "\n",
      "\n",
      "All free model parameters will be estimated by RAxML\n",
      "GAMMA model of rate heterogeneity, ML estimate of alpha-parameter\n",
      "\n",
      "GAMMA Model parameters will be estimated up to an accuracy of 0.1000000000 Log Likelihood units\n",
      "\n",
      "Partition: 0\n",
      "Alignment Patterns: 305\n",
      "Name: No Name Provided\n",
      "DataType: DNA\n",
      "Substitution Matrix: GTR\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RAxML was called as follows:\n",
      "\n",
      "raxmlHPC-PTHREADS -f A -t RAxML_bipartitionsBranchLabels.raxml_rapid_spliced_cds_tree -s EBOV_CDS_splice_39_seqs_underscores.fa -m GTRGAMMA -n ANC_RECON_CDS_splice -T 3 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd spliced_cds_work/\n",
    "raxmlHPC-PTHREADS -f A -t RAxML_bipartitionsBranchLabels.raxml_rapid_spliced_cds_tree -s EBOV_CDS_splice_39_seqs_underscores.fa -m GTRGAMMA -n ANC_RECON_CDS_splice -T 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "fw = open('spliced_cds_work/RAxML_marginalAncestralStates.ANC_RECON_CDS_splice.fasta','w')\n",
    "c=0\n",
    "with open('spliced_cds_work/RAxML_marginalAncestralStates.ANC_RECON_CDS_splice','r') as f:\n",
    "    for l in f:\n",
    "        l=l.rstrip('\\n')\n",
    "        tokens = l.split(' ')\n",
    "        fw.write('>'+tokens[0]+'\\n'+tokens[1]+'\\n')\n",
    "        c+=1\n",
    "fw.close()\n",
    "print(c)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd spliced_cds_work/\n",
    "cat RAxML_marginalAncestralStates.ANC_RECON_CDS_splice.fasta EBOV_CDS_splice_39_seqs_underscores.fa > EBOV_CDS_splice_with_marginalAncestralStates.fasta\n",
    "grep -c '>' EBOV_CDS_splice_with_marginalAncestralStates.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITIONS #\n",
    "\n",
    "def check_and_count(tree, old_count, snp, major_variant, minor_variant, minor_freq):\n",
    "    check = minor_major_monophyly_check(tree, snp, major_variant, minor_variant, minor_freq)\n",
    "    return tuple(map(lambda x, y: x + y, old_count, check))\n",
    "\n",
    "def minor_major_monophyly_check(tree, snp, major_variant, minor_variant, minor_freq):\n",
    "#     print(snp, major_variant, minor_variant)\n",
    "    count = (0,0,0,0)\n",
    "    if minor_freq==1:\n",
    "        snp_classifier['only_occurs_once'].append((snp, major_variant+ ':'+minor_variant))\n",
    "        count = (1,0,0,0)\n",
    "    else:\n",
    "        minor_monophyly_check = tree.check_monophyly(values=[minor_variant], target_attr=\"snp\") \n",
    "        if minor_monophyly_check[0]:\n",
    "            snp_classifier['minor_monophyly'].append((snp, major_variant+ ':'+minor_variant))\n",
    "            count = (0,1,0,0)\n",
    "        elif not minor_monophyly_check[0]:\n",
    "            major_monophyly_check = tree.check_monophyly(values=[major_variant], target_attr=\"snp\")\n",
    "            if major_monophyly_check[0]:\n",
    "                snp_classifier['major_monophyly'].append((snp, major_variant+ ':'+minor_variant))\n",
    "                count = (0,0,1,0)\n",
    "            elif not major_monophyly_check[0]:\n",
    "                snp_classifier['not_monophyly'].append((snp, major_variant + ':'+minor_variant))\n",
    "                count = (0,0,0,1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE SNP DICT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE SNP DICT #\n",
    "snp_dict = {}\n",
    "\n",
    "a = AlignIO.read(\"spliced_cds_work/EBOV_CDS_splice_with_marginalAncestralStates.fasta\",\"fasta\")\n",
    "aa = np.array([list(rec) for rec in a], np.character, order=\"F\")\n",
    "\n",
    "for i in range(len(a[0])): #for each base up to the length of the alignment\n",
    "    bp = aa[:, i:i+1] \n",
    "    bases = []\n",
    "    for item in bp:\n",
    "        bases.append(item[0])\n",
    "    c =1\n",
    "    if i < 100 or i > 5000: #18880 for full genome\n",
    "        for ambig in ['N','?','-']:\n",
    "            if ambig in bases:\n",
    "                c +=1\n",
    "        if len(set(bases))>c:\n",
    "            snp_dict['snp_'+str(i+1)]=bases\n",
    "    elif 'N' in bases:\n",
    "        if len(set(bases))>2:\n",
    "            snp_dict['snp_'+str(i+1)]=bases\n",
    "    else:\n",
    "        if len(set(bases))>1:\n",
    "            snp_dict['snp_'+str(i+1)]=bases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE INDEX DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE INDEX DICT #\n",
    "# LETS YOU KNOW WHICH ITEM IN THE SNP DICT VALUE (I.E. BASES LIST) CORRESPONDS TO WHICH RECORD IN THE ALIGNMENT #\n",
    "index_dict = {}\n",
    "c=0\n",
    "for record in a:\n",
    "    c +=1\n",
    "    index_dict[record.id]= c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COUNTING AND CLASSIFYING SNPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING COUNTERS #\n",
    "simple_cases_counter = 0\n",
    "complex_cases_counter = 0\n",
    "early_gap =0\n",
    "late_gap =0\n",
    "ambiguous_base=0\n",
    "\n",
    "SIMPLE = (0,0,0,0)\n",
    "COMPLEX = (0,0,0,0)\n",
    "\n",
    "# CLASSIFYING THE SNPS #\n",
    "\n",
    "snp_classifier = collections.defaultdict(list)\n",
    "\n",
    "for snp in sorted(snp_dict, key= lambda x: float(x.split('_')[1])): \n",
    "    snp_count = Counter()\n",
    "    \n",
    "    t = Tree(\"spliced_cds_work/RAxML_nodeLabelledRootedTree.ANC_RECON_CDS_splice\",format=8)\n",
    "    for node in t.traverse(\"preorder\"):\n",
    "        if node.is_leaf():\n",
    "            node.add_features(snp=snp_dict[snp][index_dict[node.name]-1])  #add snp annotations to each tip\n",
    "            snp_count[snp_dict[snp][index_dict[node.name]-1]]+=1 #count the leaf snp frequency\n",
    "            \n",
    "    snp_count = snp_count.most_common()   \n",
    "    \n",
    "    major_variant = snp_count[0][0]\n",
    "\n",
    "    # SIMPLE CASE #\n",
    "    if len(snp_count)==2:\n",
    "        # e.g. snp_189 [('G', 68), ('A', 4)]\n",
    "        simple_cases_counter +=1 \n",
    "        \n",
    "        minor_variant = snp_count[1][0]\n",
    "        minor_freq = snp_count[1][1]\n",
    "        \n",
    "        if minor_variant != 'N' and minor_variant != '?':\n",
    "            SIMPLE = check_and_count(t, SIMPLE, snp, major_variant, minor_variant, minor_freq)            \n",
    "    else:\n",
    "        # COMPLEX CASE #\n",
    "        # eg. snp_18913 [('G', 68), ('N', 3), ('A', 2), ('R', 2), ('-', 2)] #\n",
    "        complex_cases_counter +=1 \n",
    "        \n",
    "        for k in snp_count[1:]:\n",
    "#             print(k)\n",
    "            minor_variant = k[0]\n",
    "            minor_freq = k[1]\n",
    "        \n",
    "#             if float(snp.split('_')[1]) < 100 and k[0]=='-':\n",
    "#                 early_gap += 1\n",
    "            if k[0]=='N' or k[0]=='?':\n",
    "                ambiguous_base += 1\n",
    "            elif float(snp.split('_')[1]) > 5000:\n",
    "#                 if float(snp.split('_')[1]) > 18900 and k[0]=='-':\n",
    "#                     late_gap +=1\n",
    "#                 else:\n",
    "                new_id_list = [i for i in index_dict.keys() if i not in ['EBOV_JQ352763_Kikwit_Kikwit_DRC_1995-05-04','EBOV_HQ613403_M-M_DRC_2007-08-31','EBOV_HQ613402_034-KS_DRC_2008-12-31']]    \n",
    "                t.prune(new_id_list)\n",
    "                COMPLEX = check_and_count(t, COMPLEX, snp, major_variant, minor_variant, minor_freq)  \n",
    "            else:\n",
    "                COMPLEX = check_and_count(t, COMPLEX, snp, major_variant, minor_variant, minor_freq) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT PRINT OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### RESULTS #####\n",
      "Simple, Complex, Total:  340 + 514 = 854\n",
      "\n",
      "\n",
      "##### SNP Classifier Dict #####\n",
      "only_occurs_once (All: 159 , Unique: 157 )\n",
      "not_monophyly (All: 51 , Unique: 51 )\n",
      "major_monophyly (All: 58 , Unique: 58 )\n",
      "minor_monophyly (All: 599 , Unique: 591 )\n",
      "\n",
      "\n",
      "##### Simple cases #####\n",
      "(only a single snp, minor monophyly, major monophyly, not monophyletic)\n",
      "(62, 239, 18, 21)\n",
      "\n",
      "\n",
      "##### Not quite as simple cases #####\n",
      "minor N or ?  507\n",
      "early -  0\n",
      "late -  0\n",
      "(only a single snp, minor monophyly, major monophyly, not monophyletic)\n",
      "(97, 360, 40, 30)\n",
      "\n",
      "\n",
      "##### Tally of the two #####\n",
      "( 159 599 58 51 )\n"
     ]
    }
   ],
   "source": [
    "# RESULT PRINT OUT #\n",
    "print '##### RESULTS #####'\n",
    "print 'Simple, Complex, Total: ',simple_cases_counter, '+', complex_cases_counter,'=', simple_cases_counter+complex_cases_counter\n",
    "print '\\n'\n",
    "print '##### SNP Classifier Dict #####'\n",
    "for k in snp_classifier:\n",
    "    key_dict = collections.defaultdict(list)\n",
    "    for i in snp_classifier[k]:\n",
    "        key_dict[i[0]].append(i[1])\n",
    "    print k,'(All:', len(snp_classifier[k]), ', Unique:', len(key_dict), ')'\n",
    "print '\\n'    \n",
    "print '##### Simple cases #####'\n",
    "print '(only a single snp, minor monophyly, major monophyly, not monophyletic)'\n",
    "print SIMPLE\n",
    "print '\\n'        \n",
    "print '##### Not quite as simple cases #####'\n",
    "print 'minor N or ? ', ambiguous_base\n",
    "print 'early - ', early_gap\n",
    "print 'late - ', late_gap\n",
    "print '(only a single snp, minor monophyly, major monophyly, not monophyletic)'\n",
    "print COMPLEX\n",
    "print '\\n'   \n",
    "print '##### Tally of the two #####'\n",
    "print '(', SIMPLE[0]+COMPLEX[0], SIMPLE[1]+COMPLEX[1], SIMPLE[2]+COMPLEX[2], SIMPLE[3]+COMPLEX[3], ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENE LOCATION DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13582\n"
     ]
    }
   ],
   "source": [
    "gene={}\n",
    "for i in range(1,2221):\n",
    "    gene[i]=\"NP\"\n",
    "for i in range(2221,3244):\n",
    "    gene[i]=\"VP35\"\n",
    "for i in range(3244,4225):\n",
    "    gene[i]=\"VP40\"\n",
    "for i in range(4225,5321):\n",
    "    gene[i]=\"GP\"\n",
    "for i in range(5321,6188):\n",
    "    gene[i]=\"VP30\"\n",
    "for i in range(6188,6944):\n",
    "    gene[i]=\"VP24\"\n",
    "for i in range(6944,13583):\n",
    "    gene[i]=\"L\"\n",
    "print(len(gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw=open('spliced_cds_work/identify_and_classify_snps_results.csv','w')\n",
    "fw.write('Type,SNP,Major,Minor,Position,Gene,Position_in_Codon\\n')\n",
    "for k in snp_classifier:\n",
    "    for i in snp_classifier[k]:\n",
    "        location = int(i[0].split('_')[1])\n",
    "        fw.write('{},{},{},{},{},{},{}\\n'.format(k, i[1], i[1].split(':')[0], i[1].split(':')[1], location, gene[location], location%3))\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
